{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57b8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060c3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# ZIP_PATH = \"./face images.zip\"\n",
    "\n",
    "# with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"./\")\n",
    "\n",
    "# print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00573be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR ='/work/sharedrive/Lab/khanjan.damani/Car Detection Using Pytorch CNN'\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "ANN_DIR = os.path.join(DATA_DIR, \"faces.csv\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [IMG_DIR, ANN_DIR]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Warning: {path} not found. Check your dataset extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7d1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Face Detection Dataset (FINAL – STABLE & DETECTION-SAFE)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "\n",
    "class FaceDetectionDataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_file, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Remove invalid rows\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "        # Unique image names\n",
    "        self.image_names = self.df[\"image_name\"].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.images_dir, image_name)\n",
    "\n",
    "        # -------------------------------\n",
    "        # Safe image loading\n",
    "        # -------------------------------\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except (UnidentifiedImageError, FileNotFoundError):\n",
    "            # Neutral dummy sample (VERY IMPORTANT FIX)\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_bbox = torch.tensor(\n",
    "                [0.5, 0.5, 0.5, 0.5], dtype=torch.float32\n",
    "            )\n",
    "            return dummy_image, dummy_bbox\n",
    "\n",
    "        # -------------------------------\n",
    "        # Read annotation\n",
    "        # -------------------------------\n",
    "        row = self.df[self.df[\"image_name\"] == image_name].iloc[0]\n",
    "\n",
    "        img_w = row[\"width\"]\n",
    "        img_h = row[\"height\"]\n",
    "\n",
    "        x0 = row[\"x0\"] / img_w\n",
    "        y0 = row[\"y0\"] / img_h\n",
    "        x1 = row[\"x1\"] / img_w\n",
    "        y1 = row[\"y1\"] / img_h\n",
    "\n",
    "        # Clamp bounding box to [0, 1]\n",
    "        bbox = torch.tensor(\n",
    "            [\n",
    "                max(0.0, min(x0, 1.0)),\n",
    "                max(0.0, min(y0, 1.0)),\n",
    "                max(0.0, min(x1, 1.0)),\n",
    "                max(0.0, min(y1, 1.0)),\n",
    "            ],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # -------------------------------\n",
    "        # Apply transforms\n",
    "        # -------------------------------\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301631d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 2204\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Transforms and DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Image size for the CNN\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Image transformations\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "train_dataset = FaceDetectionDataset(\n",
    "    images_dir=IMG_DIR,\n",
    "    csv_file=ANN_DIR,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Total training images:\", len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c5c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: CNN Backbone for Face Detection (UPDATED)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FaceCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceCNN, self).__init__()\n",
    "\n",
    "        # -------------------------------\n",
    "        # CNN Backbone\n",
    "        # -------------------------------\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 224 -> 112\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 112 -> 56\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 56 -> 28\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 28 -> 14\n",
    "        )\n",
    "\n",
    "        # Global pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # -------------------------------\n",
    "        # Bounding Box Regressor (IMPORTANT)\n",
    "        # -------------------------------\n",
    "        self.bbox_head = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(128, 4),\n",
    "            nn.Sigmoid()   # CRITICAL: outputs in [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # [B, 256]\n",
    "        bbox = self.bbox_head(x)\n",
    "        return bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d863aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model, loss function, and optimizer initialized\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Loss function and optimizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Device setup (GPU-safe)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Initialize model\n",
    "model = FaceCNN().to(device)\n",
    "\n",
    "# Bounding box regression loss\n",
    "criterion = nn.SmoothL1Loss(beta=0.5)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=2e-4,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "print(\"Model, loss function, and optimizer initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Training loop\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for images, boxes in train_loader:\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(preds, boxes)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Accuracy using IoU\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    box format: [x1, y1, x2, y2] (normalized 0–1)\n",
    "    \"\"\"\n",
    "    x1 = torch.max(box1[0], box2[0])\n",
    "    y1 = torch.max(box1[1], box2[1])\n",
    "    x2 = torch.min(box1[2], box2[2])\n",
    "    y2 = torch.min(box1[3], box2[3])\n",
    "\n",
    "    inter = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    union = area1 + area2 - inter\n",
    "\n",
    "    return inter / union if union > 0 else torch.tensor(0.0)\n",
    "\n",
    "\n",
    "def detection_accuracy(model, dataloader, device, iou_threshold=0.5):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iou_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, gt_boxes in dataloader:\n",
    "            images = images.to(device)\n",
    "            gt_boxes = gt_boxes.to(device)\n",
    "\n",
    "            preds = model(images)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                iou = compute_iou(preds[i], gt_boxes[i])\n",
    "                iou_sum += iou.item()\n",
    "\n",
    "                if iou >= iou_threshold:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    avg_iou = iou_sum / total\n",
    "    acc = correct / total\n",
    "\n",
    "    return acc, avg_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352dcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, avg_iou = detection_accuracy(\n",
    "    model,\n",
    "    train_loader,\n",
    "    device,\n",
    "    iou_threshold=0.5\n",
    ")\n",
    "\n",
    "print(f\"Training Detection Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Average IoU: {avg_iou:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Visualize predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def visualize_predictions(dataset, model, device, num_samples=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image, gt_box = dataset[i]\n",
    "\n",
    "        input_img = image.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_box = model(input_img).cpu().squeeze(0)\n",
    "\n",
    "        # Convert tensor image to numpy\n",
    "        img_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "\n",
    "        H, W, _ = img_np.shape\n",
    "\n",
    "        # Ground truth bbox\n",
    "        gt = gt_box.numpy()\n",
    "        gt_x1, gt_y1 = int(gt[0] * W), int(gt[1] * H)\n",
    "        gt_x2, gt_y2 = int(gt[2] * W), int(gt[3] * H)\n",
    "\n",
    "        # Predicted bbox\n",
    "        pb = pred_box.numpy()\n",
    "        pb_x1, pb_y1 = int(pb[0] * W), int(pb[1] * H)\n",
    "        pb_x2, pb_y2 = int(pb[2] * W), int(pb[3] * H)\n",
    "\n",
    "        ax = plt.subplot(1, num_samples, i + 1)\n",
    "        ax.imshow(img_np)\n",
    "\n",
    "        # Ground truth (GREEN)\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle(\n",
    "                (gt_x1, gt_y1),\n",
    "                gt_x2 - gt_x1,\n",
    "                gt_y2 - gt_y1,\n",
    "                fill=False,\n",
    "                edgecolor=\"green\",\n",
    "                linewidth=2,\n",
    "                label=\"GT\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Prediction (RED)\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle(\n",
    "                (pb_x1, pb_y1),\n",
    "                pb_x2 - pb_x1,\n",
    "                pb_y2 - pb_y1,\n",
    "                fill=False,\n",
    "                edgecolor=\"red\",\n",
    "                linewidth=2,\n",
    "                label=\"Pred\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run visualization\n",
    "visualize_predictions(train_dataset, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeba7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
